#!/usr/bin/env python

import argparse
import os
import json
import glob
import re
import datetime as dt
from utils.batch_utils import get_job_id, append_to_json
from utils.miscHelpers import condMkDirFile, tail, getBinIdx


def read_gen_config(genfile):
    """Read the generator settings from the generator dir"""
    gendir = os.path.dirname(genfile)
    with open('/'.join([gendir, 'input_lambdas.json']), 'r') as f:
        data = json.load(f)
    return data


def submit_job(datafile, reffile, outfile):
    """Submit a batch job that runs one fit using the passed files"""
    condMkDirFile(outfile)
    outdir = os.path.dirname(outfile)

    # combine data and refernce generator settings into one json and dump it to the output directory
    comb_config = {'data': read_gen_config(datafile),
                   'ref': read_gen_config(reffile)}
    with open('/'.join([outdir, 'input_lambdas.json']), 'w') as f:
        json.dump(comb_config, f, indent=2)

    batch_script = '/'.join([os.environ['WORK'], 'NewPolMethodTests/Framework/polFit/batchRunIterative.sh'])
    cmd_list = ['sbatch', batch_script, datafile, reffile, 'genData', outfile]

    # batch submission yields only 1 element in the list, from which the job id will be
    # retrieved. second index is for getting first (and only) element of tuple returned
    # by tail
    job_id = get_job_id(list(tail(cmd_list))[0][0])

    append_to_json('/'.join([outdir, 'batch_job_info.json']),
                   {'job_id': job_id,
                    'sub_time': str(dt.datetime.now()),
                    'datafile': datafile,
                    'reffile': reffile,
                    'outfile': os.path.basename(outfile)
                   })


def get_io_combi(datafile, reffile, outbase, only_same_gen=True):
    """
    Get the three tuple of datafile, inputfile, outputfile
    """
    def get_lth(filename):
        m = re.search('lth_(-?[0-9]+p[0-9]{2})', filename)
        if m:
            return m.group(1)
        else:
            return None

    data_gen = getBinIdx(datafile, 'gen_')
    ref_gen = getBinIdx(reffile, 'gen_')
    if only_same_gen and ref_gen != data_gen:
        return None

    data_lth = get_lth(datafile)
    ref_lth = get_lth(reffile)

    outdir = '_'.join(['data', 'lth', data_lth, 'ref', 'lth', ref_lth])
    ofn = '_'.join(['fit', 'results', 'datagen', str(data_gen), 'refgen', str(ref_gen)])
    outfile = '/'.join([outbase, outdir, ofn + '.root'])

    return (datafile, reffile, outfile)


def get_combinations(inputbase, outbase, only_same_gen=True):
    """
    Get the combinations of data and reference files and produce the appropriate output
    file for it.
    """
    combis = []
    gen_files = glob.glob('/'.join([inputbase, 'lth_*_lph_*_ltp_*/genData_gen_*.root']))

    for df in gen_files:
        for rf in gen_files:
            combi = get_io_combi(df, rf, outbase, only_same_gen)
            if combi is not None:
                combis.append(combi)

    return combis


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='script for submitting fitting jobs to '
                                     'the batch system.')
    parser.add_argument('genDataDir', help='directory that holds the generated ToyMC data'
                        ' in the format as it is generated by \'generateToyMC.py\'')
    parser.add_argument('outdir', help='output base directory for the fit results')
    parser.add_argument('-a', '--allCombis', action='store_true', dest='allCombis',
                        default=False, help='run all possible combinations of generations,'
                        ' instead of only running same generation data and reference')
    parser.add_argument('-c', '--combinations', help='run specific combination of passed files',
                        nargs='+', dest='combifiles', default=None)


    args = parser.parse_args()

    if len(args.combifiles) not in (0, 2):
        parser.error('Need non or exactly two arguments')

    if len(args.combifiles) > 0:
        data_ref_combis = [get_io_combi(args.combifiles[0], args.combifiles[1], args.outdir, True)]
    else:
        data_ref_combis = get_combinations(args.genDataDir, args.outdir, not args.allCombis)

    for (datan, refn, outn) in data_ref_combis:
        submit_job(datan, refn, outn)

    print('Submitted {} jobs to the batch system'.format(len(data_ref_combis)))
