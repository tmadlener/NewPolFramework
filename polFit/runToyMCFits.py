#!/usr/bin/env python

import argparse
import os
import json
import glob
import re
import datetime as dt
from utils.batch_utils import get_job_id, append_to_json
from utils.miscHelpers import condMkDirFile, tail, getBinIdx


def read_gen_config(genfile):
    """Read the generator settings from the generator dir"""
    gendir = os.path.dirname(genfile)
    with open('/'.join([gendir, 'input_lambdas.json']), 'r') as f:
        data = json.load(f)
    return data


def submit_job(datafile, reffile, outfile):
    """Submit a batch job that runs one fit using the passed files"""
    condMkDirFile(outfile)
    outdir = os.path.dirname(outfile)

    # combine data and refernce generator settings into one json and dump it to the output directory
    comb_config = {'data': read_gen_config(datafile),
                   'ref': read_gen_config(reffile)}
    with open('/'.join([outdir, 'input_lambdas.json']), 'w') as f:
        json.dump(comb_config, f, indent=2)

    batch_script = '/'.join([os.environ['WORK'], 'NewPolMethodTests/Framework/polFit/batchRunIterative.sh'])
    cmd_list = ['sbatch', batch_script, datafile, reffile, 'genData', outfile]

    # batch submission yields only 1 element in the list, from which the job id will be
    # retrieved. second index is for getting first (and only) element of tuple returned
    # by tail
    job_id = get_job_id(list(tail(cmd_list))[0][0])

    append_to_json('/'.join([outdir, 'batch_job_info.json']),
                   {'job_id': job_id,
                    'sub_time': str(dt.datetime.now()),
                    'datafile': datafile,
                    'reffile': reffile,
                    'outfile': os.path.basename(outfile)
                   })


def get_combinations(inputbase, outbase, only_same_gen=True):
    """
    Get the combinations of data and reference files and produce the appropriate output
    file for it.
    """
    combis = []
    gen_files = glob.glob('/'.join([inputbase, 'lth_*_lph_*_ltp_*/genData_gen_*.root']))

    def get_lth(filename):
        m = re.search('lth_(-?[0-9]+p[0-9]{2})', filename)
        if m:
            return m.group(1)
        else:
            return None

    for df in gen_files:
        data_lth = get_lth(df)
        data_gen = getBinIdx(df, 'gen_')

        for rf in gen_files:
            ref_lth = get_lth(rf)
            ref_gen = getBinIdx(rf, 'gen_')

            # if only same gen is true, only combine gen_X from data with gen_X from reference
            # in this way we cut down significantly on combinatorics
            if only_same_gen and ref_gen != data_gen:
                continue

            outdir = '_'.join(['data', 'lth', data_lth, 'ref', 'lth', ref_lth])
            ofn = '_'.join(['fit', 'results', 'datagen', str(data_gen), 'refgen', str(ref_gen)])
            outfile = '/'.join([outbase, outdir, ofn + '.root'])

            combis.append((df, rf, outfile))

    return combis


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='script for submitting fitting jobs to '
                                     'the batch system.')
    parser.add_argument('genDataDir', help='directory that holds the generated ToyMC data'
                        ' in the format as it is generated by \'generateToyMC.py\'')
    parser.add_argument('outdir', help='output base directory for the fit results')
    parser.add_argument('-a', '--allCombis', action='store_true', dest='allCombis',
                        default=False, help='run all possible combinations of generations,'
                        ' instead of only running same generation data and reference')

    args = parser.parse_args()

    data_ref_combis = get_combinations(args.genDataDir, args.outdir, not args.allCombis)
    for (datan, refn, outn) in data_ref_combis:
        submit_job(datan, refn, outn)

    print('Submitted {} jobs to the batch system'.format(len(data_ref_combis)))
